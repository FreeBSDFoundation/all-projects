# Jun 19, 2025

Attendees: Li-Wen Hsu,  Moin Rahman, Ed Maste, Alice Sowerby, Joseph Mingrone, Siva Mahadevan. 

## Work items (numbering starts at 3\)

3. Improve quality of incoming commits  
   * Now complete  
4. Pre-merge CI  
   * Now complete  
5. Environment Metadata  
   * Started looking at it, running CI tests with Cloud services. Moin has discussed it with Li-Wen.  
6. Extend CI to the Ports tree.  
   * Joe waiting to get a jail in the cluster (waiting on clusteradm to provision the hardware). Li-wen can provide a poudriere jail sooner if Joe provides some details. Note: Siva has some patches to poudriere and the ports framework to help with reproducibility but it's not yet upstreamed into the ports tree. https://reviews.freebsd.org/D50911 If Siva can let clusteradm know what infra is needed, they will find a suitable host. Moin: It can take 6 days to build the whole ports tree with tests. Li-Wen: perhaps focus on packages that are released officially.  
7. CI Threat Model  
   * Feeling happy that there is time to do this in the project.  
8. CI Management Process  
   * Not much update from Li-Wen's side. Downstream enterpriser user is still setting things up to test the docs out. They are setting up a Jenkins cluster.  
9. 3rd-party Interoperability  
   * Last week, I started doing my discovery/testing on: \- nuageinit \- it won't be sufficient for our purposes for now because at this point it does not able to run commands like cloud-init's "runcmd" \- figuring out the right combination of "cloud-init" and passing "CustomData" for the Azure instances that will be used to run CI tests \- Turns out this bug https://github.com/canonical/cloud-init/issues/6206 is a little bit of a show stopper in terms of using straight on 'cloud-init' as a setting in Waagent (the client that Azure uses to communicate with the VM) \- Currently, I am finding the last few details on passing data to the VMs Next: \- I am going to start working on running the CI tests Li-Wen: other people seem to be doing fixes on nuageinit and cloudinit, so it may be worth her reaching out to the community to see what they are doing. Depending on her availability, someone may need to help her (she sent Li-Wen a message but Li-Wen has limited availability).  
10. Automated analysis in tests  
    * Li-Wen is setting this up in CI, aiming for end-June or mid-July. This was discussed at BSDCan.  
11. Test Case Management  
    * We want to get away from the feeling that the tests are always broken just because there are a few "always broken" tests. We want a tool or process for being able to exclude known failing tests so that newly-failing tests can be identified and actionable. Perhaps cross-check with bugzilla to know which tests are known to be broken. And if a test newly fails, can we automatically open a bug in bugzilla. Possibly use test success/fail statistics to further identify which tests are low quality. https://plugins.jenkins.io/flaky-test-handler/ @Li-Wen Hsu is this currently in place?  
12. Granular Debugging  
    * This could be a high impact item, but also could be a yak to shave that takes up a lot of time and little to show for it. "Who broke the build?" fits in with ID 11\. This functionality would also make visible some causality with breaking the build and potentially create a cultural change (and all that implies).  
13. Documentation  
    * Not yet started, Moin plans to write it in the wiki. Will start with this after running CI on remote cloud is complete.
